{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention_CycleGAN_orig_impl.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hlxUCTXB6Odx",
        "colab": {}
      },
      "source": [
        "# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "# !unzip ngrok-stable-linux-amd64.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UTs73bQsNQg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50cca75a-e1f7-4fd3-85a0-a40601a04b5d"
      },
      "source": [
        "get_ipython().system_raw('tensorboard --logdir ./summaries --host 0.0.0.0 --port 6006 &')\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://c0ea41bb.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYlDPsDVu5c2",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrVFKv61i1bF",
        "colab_type": "code",
        "outputId": "f8beb713-57c0-4c3c-ced5-0f6ea491aa9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "source": [
        "! git clone https://github.com/Tymyan1/datasets.git\n",
        "! pip install tensorflow-gpu==2.0.0-alpha0\n",
        "! pip install tensorflow-addons\n",
        "! pip install pydrive\n",
        "! pip install zipfile36"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'datasets' already exists and is not an empty directory.\n",
            "Requirement already satisfied: tensorflow-gpu==2.0.0-alpha0 in /usr/local/lib/python3.6/dist-packages (2.0.0a0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.9)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.1.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.7)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.0.dev2019030115)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.33.4)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.16.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.0a20190301)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (0.15.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (41.0.1)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons) (1.12.0)\n",
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.6.7)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.11.3)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.5)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (1.12.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.5)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied: zipfile36 in /usr/local/lib/python3.6/dist-packages (0.1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyYDmQ3JixKY",
        "colab_type": "text"
      },
      "source": [
        "# Util"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utmClv0Tu78p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pathlib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def linear_decayed_lr(epoch, lr, total_epochs, non_decayed_epochs=100):\n",
        "    if epoch < non_decayed_epochs:\n",
        "        return lr\n",
        "    return lr * (1 - 1 / (epoch - non_decayed_epochs) * (total_epochs - epoch))\n",
        "\n",
        "def tau_thres(input_, tau=0.1):\n",
        "    return np.where(input_ <= tau, 0, input_)\n",
        "\n",
        "# @tf.function\n",
        "def get_bg_map(att_map):\n",
        "    bg = (1 - mapa)\n",
        "    return bg\n",
        "\n",
        "# @tf.function\n",
        "def compose_img(att, fg, bg):\n",
        "    return (att * fg) + bg\n",
        "\n",
        "# based on https://github.com/gabrielpierobon/cnnshapes/blob/master/README.md\n",
        "# given the input img, plots all the activations along the whole network \n",
        "def show_flow(model, img):\n",
        "    # build a model\n",
        "    layer_outputs = [layer.output for layer in model.layers]\n",
        "    _model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "    \n",
        "    activations = _model.predict(img)\n",
        "    \n",
        "    path = 'layer_imgs/genA/'\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    \n",
        "    layer_names = []\n",
        "    for layer in model.layers:\n",
        "        layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n",
        "\n",
        "    images_per_row = 16\n",
        "    i = 0\n",
        "    for layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps\n",
        "        n_features = layer_activation.shape[-1] # Number of features in the feature map\n",
        "        size = layer_activation.shape[1] # The feature map has shape (1, size, size, n_features).\n",
        "        n_cols = n_features // images_per_row # Tiles the activation channels in this matrix\n",
        "        n_cols = max(n_cols, 1)\n",
        "        display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
        "        \n",
        "        feature_counter = 0\n",
        "        for col in range(n_cols): # Tiles each filter into a big horizontal grid\n",
        "            for row in range(images_per_row):\n",
        "                if feature_counter >=  n_features:\n",
        "                    break\n",
        "                \n",
        "                channel_image = layer_activation[0,\n",
        "                                                 :, :,\n",
        "                                                 col * images_per_row + row]\n",
        "                channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable\n",
        "                channel_image /= channel_image.std()\n",
        "                channel_image *= 64\n",
        "                channel_image += 128\n",
        "                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "                display_grid[col * size : (col + 1) * size, # Displays the grid\n",
        "                             row * size : (row + 1) * size] = channel_image\n",
        "                feature_counter += 1\n",
        "        scale = 1. / size\n",
        "        plt.figure(figsize=(scale * display_grid.shape[1],\n",
        "                            scale * display_grid.shape[0]))\n",
        "        plt.title(layer_name)\n",
        "        plt.grid(False)\n",
        "        \n",
        "       \n",
        "        # plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
        "        plt.savefig('{}/{:03d}_{}.png'.format(path, i, layer_name), aspect='auto')#, cmap='viridis')\n",
        "        i += 1\n",
        "    print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkJhQ09FkMxo",
        "colab_type": "text"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmxcKKmokb_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from glob import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "class Data_Loader():\n",
        "    ROOT_PATH = './datasets/'\n",
        "\n",
        "    def __init__(self, name, batch_size, img_shape=(256,256,3), patch=None):\n",
        "        self.name = name\n",
        "        self.batch_size = batch_size\n",
        "        self.img_dims = (patch + (3,)) if patch else img_shape\n",
        "\n",
        "        # load in the data\n",
        "        pathsA = glob(Data_Loader.ROOT_PATH + name + '/trainA/*')\n",
        "        pathsB = glob(Data_Loader.ROOT_PATH + name + '/trainB/*')\n",
        "        countA = len(pathsA)\n",
        "        countB = len(pathsB)\n",
        "        self.n_batches = int(min(countA, countB) / self.batch_size)\n",
        "        \n",
        "        self.dsA = tf.data.Dataset.from_tensor_slices(pathsA)\n",
        "        self.dsB = tf.data.Dataset.from_tensor_slices(pathsB)\n",
        "\n",
        "        self.dsA = self.dsA.map(lambda img: _load_and_preprocess_image(img, img_dims=[self.img_dims[0], self.img_dims[1]]), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "        self.dsB = self.dsB.map(lambda img: _load_and_preprocess_image(img, img_dims=[self.img_dims[0], self.img_dims[1]]), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "        \n",
        "        self.dsA = self.dsA.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=countA))\n",
        "        self.dsB = self.dsB.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=countB))\n",
        "        \n",
        "        self.dsA = self.dsA.batch(batch_size)\n",
        "        self.dsB = self.dsB.batch(batch_size)\n",
        "        \n",
        "        self.dsA = self.dsA.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "        self.dsB = self.dsB.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "        \n",
        "        self.itA = iter(self.dsA)\n",
        "        self.itB = iter(self.dsB)\n",
        "        \n",
        "        self.it_counter = 0\n",
        "        \n",
        "        samples = {\n",
        "            'horse2zebra': ('datasets/horse2zebra/testA/n02381460_120.jpg', 'datasets/horse2zebra/testB/n02391049_1880.jpg'),\n",
        "#             'sim2larvae': ('datasets/sim2larvae/testA/view3151.png', 'datasets/sim2larvae/testB/img_331_8.png')\n",
        "            'sim2larvae': ('datasets/sim2larvae/testM/view3151.png', 'datasets/sim2larvae/testB/img_331_8.png')\n",
        "        }\n",
        "\n",
        "        self.samples = np.expand_dims(_load_and_preprocess_image(samples[name][0], [self.img_dims[0], self.img_dims[1]]), axis=0), \\\n",
        "                       np.expand_dims(_load_and_preprocess_image(samples[name][1], [self.img_dims[0], self.img_dims[1]]), axis=0)\n",
        "        \n",
        "        \n",
        "    def load_batch(self):\n",
        "        self.it_counter += 1\n",
        "        return next(self.itA), next(self.itB)\n",
        "\n",
        "    def batches_left(self):\n",
        "        return self.it_counter % self.n_batches\n",
        "    \n",
        "    def sample_batch(self):\n",
        "        return self.samples\n",
        "    \n",
        "def _load_and_preprocess_image(path, img_dims):\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, img_dims)\n",
        "    image = (image / 127.5) - 1\n",
        "    return image    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvxPZat9kgAp",
        "colab_type": "text"
      },
      "source": [
        "# Layers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wb4yPfFpkoaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "class Pad(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, paddings, mode='CONSTANT', constant_values=0, **kwargs):\n",
        "        super(Pad, self).__init__(**kwargs)\n",
        "        self.paddings = paddings\n",
        "        self.mode = mode\n",
        "        self.constant_values = constant_values\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.pad(inputs, self.paddings, mode=self.mode, constant_values=self.constant_values)\n",
        "\n",
        "\n",
        "class TauThreshold(tf.keras.layers.Layer):\n",
        "    def __init__(self, tau=0.1, **kwargs):\n",
        "        super(TauThreshold, self).__init__(**kwargs)\n",
        "        self.tau = tau\n",
        "\n",
        "    def call(self, input_):\n",
        "        zeros = tf.zeros_like(input_)\n",
        "        return tf.where(tf.less(input_, self.tau), zeros, input_)\n",
        "    \n",
        "\n",
        "class UpSample(tf.keras.layers.Layer):\n",
        "    def __init__(self, size, **kwargs):\n",
        "        super(UpSample, self).__init__(**kwargs)\n",
        "        self.size = size\n",
        "\n",
        "    def call(self, input_):\n",
        "        return tf.image.resize(input_, size=self.size, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooP3ztummEQj",
        "colab_type": "text"
      },
      "source": [
        "# Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSU6MTmSmKNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import json\n",
        "\n",
        "class LinearDecay(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    \"\"\"\n",
        "    Linear learning rate decay down to 0 applied after decay_offset_steps steps\n",
        "    \"\"\"\n",
        "    def __init__(self, lr, total_steps, decay_offset_steps):\n",
        "        self.lr = lr\n",
        "        self.total_steps = total_steps\n",
        "        self.decay_offset_steps = decay_offset_steps\n",
        "        #1.13 version bellow\n",
        "#         self.current_learning_rate = tf.Variable(initial_value=lr, trainable=False, dtype=tf.float32)\n",
        "\n",
        "#     def __call__(self, step):\n",
        "#         self.current_learning_rate.assign(tf.cond(\n",
        "#             step >= self.decay_offset_steps,\n",
        "#             true_fn=lambda: self.lr * (\n",
        "#                         1 - 1 / (self.total_steps - self.decay_offset_steps) * (step - self.decay_offset_steps)),\n",
        "#             false_fn=lambda: self.lr\n",
        "#         ))\n",
        "#         return self.current_learning_rate\n",
        "\n",
        "    @tf.function\n",
        "    def __call__(self, step):\n",
        "        if step >= self.decay_offset_steps:\n",
        "            return self.lr * (1 - 1 / (self.total_steps - self.decay_offset_steps) * (step - self.decay_offset_steps))\n",
        "        return self.lr\n",
        "    \n",
        "    def get_config(self):\n",
        "        return json.dumps({\n",
        "            'lr': self.lr,\n",
        "            'total_steps': self.total_steps,\n",
        "            'decay_offset_steps': self.decay_offset_steps\n",
        "#             'current_learning_rate': self.current_learning_rate\n",
        "        })\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvnbBoHunB7a",
        "colab_type": "text"
      },
      "source": [
        "# ItemPool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7kYlpzhnJvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import stack\n",
        "import random\n",
        "\n",
        "class ItemPool(object):\n",
        "    def __init__(self, size=50):\n",
        "        self.size = size\n",
        "        self.queue = []\n",
        "\n",
        "    def call(self, elem):\n",
        "        if len(self.queue) < self.size:\n",
        "            self.queue.append(np.expand_dims(elem), axis=0)\n",
        "            return elem\n",
        "        else:\n",
        "            if random.random() < .5:\n",
        "                # replace a random element with the new one\n",
        "                index = random.randint(0, self.size-1)\n",
        "                tmp = self.queue[index]\n",
        "                self.queue[index] = np.expand_dims(elem, axis=0)\n",
        "                return tmp\n",
        "            else:\n",
        "                # just return the current element without adding\n",
        "                return elem\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkKQRfFdnXit",
        "colab_type": "text"
      },
      "source": [
        "# Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gwqLZVPnZr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "def _g_conv_layer(input_, filters, filter_size, norm='instance', strides=2, pad='VALID', relu=True):\n",
        "#     input_ = tf.cast(input_, tf.float32)\n",
        "    conv = tf.keras.layers.Conv2D(filters, kernel_size=filter_size, padding=pad, strides=strides)(input_)\n",
        "    if norm == 'instance':\n",
        "        conv = tfa.layers.InstanceNormalization()(conv)\n",
        "    if relu == True:\n",
        "        conv = tf.keras.layers.ReLU()(conv)\n",
        "    return conv\n",
        "\n",
        "def _g_res_block(input_, norm='instance'):\n",
        "    filters = input_.shape[-1]\n",
        "    out = Pad([[0, 0], [1, 1], [1, 1], [0, 0]], mode='REFLECT')(input_)\n",
        "#     out = input_\n",
        "    out = _g_conv_layer(out, filters, norm=norm, filter_size=3, strides=1, pad='VALID', relu=True)\n",
        "    out = tf.keras.layers.ReLU()(out)\n",
        "\n",
        "    out = Pad([[0, 0], [1, 1], [1, 1], [0, 0]], mode='REFLECT')(out)\n",
        "    out = _g_conv_layer(out, filters, norm=norm, filter_size=3, strides=1, pad='VALID', relu=False)\n",
        "    out = tf.keras.layers.add([input_, out])\n",
        "#     out = tf.keras.layers.ReLU()(out) #TODO enable??\n",
        "    return out\n",
        "\n",
        "def _g_deconv_layer(input_, filters, filter_size, pad='SAME', norm='instance'):\n",
        "    size = (input_.shape[1] * 2,) + (input_.shape[2] * 2,)\n",
        "#     out = UpSample(size=size)(input_)\n",
        "#     out = Pad([[0, 0], [1, 1], [1, 1], [0, 0]], mode='REFLECT')(out)\n",
        "#     out = tf.keras.layers.Conv2D(input_.shape[-1], kernel_size=3, padding='VALID', strides=1)(out)\n",
        "    out = tf.keras.layers.Conv2DTranspose(filters, kernel_size=filter_size, strides=2, padding=pad)(input_)\n",
        "    if norm == 'instance':\n",
        "        out = tfa.layers.InstanceNormalization()(out)\n",
        "    out = tf.keras.layers.ReLU()(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_generator(input_shape, name):\n",
        "\n",
        "    norm = 'instance'\n",
        "    \n",
        "    model = input_ = tf.keras.layers.Input(shape=input_shape)\n",
        "    \n",
        "    # c7s1-32-R\n",
        "    model = Pad([[0, 0], [3, 3], [3, 3], [0, 0]], mode='REFLECT')(model)\n",
        "    model = _g_conv_layer(model, 32, filter_size=7, strides=1, pad='VALID', norm=norm)\n",
        "    \n",
        "    # upsampling\n",
        "    # c3s2-64-R\n",
        "    model = _g_conv_layer(model, filters=64, filter_size=3, strides=2, pad='SAME', norm=norm)\n",
        "    # c3s2-128-R\n",
        "    model = _g_conv_layer(model, filters=128, filter_size=3, strides=2, pad='SAME', norm=norm)\n",
        "    \n",
        "    # residual blocks\n",
        "    # r128 * 9\n",
        "    for i in range(9):\n",
        "        model = _g_res_block(model)\n",
        "    \n",
        "    \n",
        "    # downsampling\n",
        "    # tc64s2\n",
        "    model = _g_deconv_layer(model, 64, 3, pad='SAME', norm=norm)\n",
        "    # tc32s2\n",
        "    model = _g_deconv_layer(model, 32, 3, pad='SAME', norm=norm)\n",
        "    \n",
        "    # c3s1-3-T\n",
        "    model = Pad([[0, 0], [3, 3], [3, 3], [0, 0]], mode='REFLECT')(model)\n",
        "    model = tf.keras.layers.Conv2D(filters=3, kernel_size=7, strides=1, padding='VALID')(model) # 3 img channels\n",
        "    model = tf.keras.layers.Activation('tanh')(model)\n",
        "\n",
        "    return tf.keras.Model(input_, model, name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgSPzQktt_HX",
        "colab_type": "text"
      },
      "source": [
        "# Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWD3Icg5uAha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "def _discriminator_layer(input_, input_nn, filters, filter_size, strides, norm='instance'):\n",
        "    \"\"\"\n",
        "    :param input_:\n",
        "    :param filters:\n",
        "    :param filter_size:\n",
        "    :param norm:\n",
        "    :return: Two discriminator blocks (with/without normalization layers) with shared layers\n",
        "    \"\"\"\n",
        "#     input_ = tf.cast(input_, tf.float32)\n",
        "    layer = layer_nn = tf.keras.layers.Conv2D(filters, kernel_size=filter_size, strides=strides, padding='SAME')(input_)\n",
        "    if norm=='instance':\n",
        "        layer = tfa.layers.InstanceNormalization()(layer)\n",
        "    relu = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
        "    layer = relu(layer)\n",
        "    layer_nn = relu(layer_nn)\n",
        "\n",
        "    return layer, layer_nn\n",
        "\n",
        "\n",
        "def build_discriminator(input_shape, name):\n",
        "    \"\"\"\n",
        "    :param input_shape:\n",
        "    :return: Two discriminators(with/without normalization) with shared layers\n",
        "    \"\"\"\n",
        "    \n",
        "    input_ = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "    # c4s2-64-LR\n",
        "    dis, dis_nn = _discriminator_layer(input_, input_, 64, filter_size=4, strides=2, norm='instance')\n",
        "    # c4s2-128-LR\n",
        "    dis, dis_nn = _discriminator_layer(dis, dis_nn, 128, filter_size=4, strides=2, norm='instance')\n",
        "    # c4s2-256-LR\n",
        "    dis, dis_nn = _discriminator_layer(dis, dis_nn, 256, filter_size=4, strides=2, norm='instance')\n",
        "    # c4s1-512-LR\n",
        "    dis, dis_nn = _discriminator_layer(dis, dis_nn, 512, filter_size=4, strides=1, norm='instance')\n",
        "    \n",
        "    # c4s1-1\n",
        "    last_layer = tf.keras.layers.Conv2D(1, kernel_size=4, strides=1, padding='SAME')\n",
        "    dis = last_layer(dis)\n",
        "    dis_nn = last_layer(dis_nn)\n",
        "\n",
        "    return tf.keras.Model(input_, dis, name=name), tf.keras.Model(input_, dis_nn, name=name+'_nn')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13tDEgOtuQOw",
        "colab_type": "text"
      },
      "source": [
        "# Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDyywD_6uR7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "def _a_conv_layer(input_, filters, filter_size, norm='instance', strides=2, pad='SAME', relu=True):\n",
        "    conv = tf.keras.layers.Conv2D(filters, kernel_size=filter_size, padding=pad, strides=strides)(input_)\n",
        "    if norm == 'instance':\n",
        "        conv = tfa.layers.InstanceNormalization()(conv)\n",
        "    if relu == True:\n",
        "        conv = tf.keras.layers.ReLU()(conv)\n",
        "    return conv\n",
        "\n",
        "def _a_res_block(input_, norm='instance'):\n",
        "    filters = input_.shape[-1]\n",
        "   \n",
        "    out = Pad([[0, 0], [1, 1], [1, 1], [0, 0]], mode='REFLECT')(input_)\n",
        "#     out = input_\n",
        "    out = _a_conv_layer(out, filters, norm=norm, filter_size=3, strides=1, pad='VALID', relu=False)\n",
        "    out = tf.keras.layers.ReLU()(out)\n",
        "\n",
        "    out = Pad([[0, 0], [1, 1], [1, 1], [0, 0]], mode='REFLECT')(out)\n",
        "    out = _a_conv_layer(out, filters, norm=norm, filter_size=3, strides=1, pad='VALID', relu=False)\n",
        "    out = tf.keras.layers.add([input_, out])\n",
        "#     out = tf.keras.layers.ReLU()(out) #TODO enable??\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_attention_net(input_shape, name):\n",
        "    size = (input_shape[0],) + (input_shape[1],)\n",
        "    # print(size)\n",
        "    model = input_ = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "    # c7s1-32-R\n",
        "    model = _a_conv_layer(model, filters=32, filter_size=7,  strides=1)\n",
        "    # c3s2-64-R\n",
        "    model = _a_conv_layer(model, filters=64, filter_size=3)\n",
        "    # r64\n",
        "    model = _a_res_block(model, 3)\n",
        "    # up2\n",
        "    model = tf.keras.layers.UpSampling2D(size=2, interpolation='nearest')(model)\n",
        "#     model = UpSample(size=size)(model)\n",
        "    # c3s1-64-R\n",
        "    model = _a_conv_layer(model, strides=1, filters=64, filter_size=3)\n",
        "    # up2\n",
        "#     model = tf.keras.layers.UpSampling2D(size=2, interpolation='nearest')(model)\n",
        "#     model = UpSample(size=size)(model) #TODO enable??\n",
        "    # c3s1-32-R\n",
        "    model = _a_conv_layer(model, strides=1, filters=32, filter_size=3) #TODO change to stride=1\n",
        "    # c7s1-1-S\n",
        "    model = _a_conv_layer(model, strides=1, filters=1, filter_size=7, relu=False)\n",
        "    model = tf.keras.activations.sigmoid(model)\n",
        "\n",
        "    return tf.keras.Model(input_, model, name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvnMI_PA1PGT",
        "colab_type": "text"
      },
      "source": [
        "# Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JllNkB-G1I-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cyclic_loss(gen_img, real_img): \n",
        "    return tf.reduce_mean(tf.abs(real_img - gen_img))\n",
        "\n",
        "def adversarial_loss(prediction_on_real, prediction_on_fake, prediction_on_cyclic): \n",
        "    return (2 * tf.reduce_mean(tf.math.squared_difference(prediction_on_real, 1))) + \\\n",
        "                tf.reduce_mean(tf.math.squared_difference(prediction_on_fake, 0)) + \\\n",
        "                tf.reduce_mean(tf.math.squared_difference(prediction_on_cyclic, 0))\n",
        "\n",
        "def generator_adversarial_loss(dis_prediction_of_img):\n",
        "    return tf.reduce_mean(tf.math.squared_difference(dis_prediction_of_img, 1))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm9BMYLYugbo",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3fb5OqQuh2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import datetime\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "\n",
        "class Model2(tf.keras.Model):\n",
        "    def __init__(self, epochs, data_loader, patch=(70,70), load_from_checkpoint=True, use_att=True, tau=0.1, attention_epochs_threshold=30, lr_d=0.002, lr_g=0.005, beta1=0.5, epoch_decay=100, pool_size=50, train_start=0):\n",
        "        super(tf.keras.Model, self).__init__()\n",
        "        self.data = data_loader\n",
        "        self.weights_path = 'output/' + self.data.name + '/weights.h5'\n",
        "        self.epochs = epochs\n",
        "        self.pool_size = pool_size\n",
        "        self.use_att = use_att\n",
        "        self.tau = tau\n",
        "        self.att_epoch_thresh = attention_epochs_threshold\n",
        "        self.train_start = train_start\n",
        "        \n",
        "        # Loss weights\n",
        "        self.lambda_cyclic = 10.0  # Cycle-consistency loss weight\n",
        "        self.lambda_id = 0.1 * self.lambda_cyclic  # Identity loss weight\n",
        "        \n",
        "#         # google drive authentication\n",
        "#         auth.authenticate_user()\n",
        "#         gauth = GoogleAuth()\n",
        "#         gauth.credentials = GoogleCredentials.get_application_default()\n",
        "\n",
        "        # Calculate output shape of D (PatchGAN)\n",
        "        # self.disc_patch = (self.data.img_dims[0], self.data.img_dims[1], 1)\n",
        "        self.disc_patch = (32,32,1) #TODO this is just a quickfix\n",
        "\n",
        "        # build models\n",
        "        # print(self.data.img_dims)\n",
        "        self.disA, self.disA_no_norm = build_discriminator(self.data.img_dims, 'disA')\n",
        "        self.disB, self.disB_no_norm = build_discriminator(self.data.img_dims, 'disB')\n",
        "      \n",
        "        self.genA = build_generator(self.data.img_dims, 'genA')\n",
        "        self.genB = build_generator(self.data.img_dims, 'genB')\n",
        "        self.attA = build_attention_net(self.data.img_dims, 'attA')\n",
        "        self.attB = build_attention_net(self.data.img_dims, 'attB')\n",
        "        \n",
        "\n",
        "        # lr schedulers\n",
        "        _total_steps = self.data.batches_left() * self.epochs\n",
        "        _decay_offset_steps = epoch_decay * self.epochs\n",
        "        lr_sched_d = LinearDecay(lr_d, _total_steps, _decay_offset_steps)\n",
        "        lr_sched_g = LinearDecay(lr_g, _total_steps, _decay_offset_steps)\n",
        "        \n",
        "        # set the optimizers\n",
        "        self.optimizer_d = tf.keras.optimizers.Adam(learning_rate=lr_sched_d, beta_1=beta1)\n",
        "        self.optimizer_g = tf.keras.optimizers.Adam(learning_rate=lr_sched_g, beta_1=beta1)\n",
        "        \n",
        "        vars_genA_att = np.concatenate([self.genA.trainable_variables, self.attA.trainable_variables])\n",
        "        vars_genB_att = np.concatenate([self.genB.trainable_variables, self.attB.trainable_variables])\n",
        "#         self.tr = self.optimizer_g.minimize(total_loss, var_list=vars_genA_att)\n",
        "\n",
        "        #TODO move?\n",
        "        if load_from_checkpoint:\n",
        "            self.load_weights(self.weights_path)\n",
        "\n",
        "        # inputs\n",
        "        imgA = tf.keras.layers.Input(shape=self.data.img_dims)\n",
        "        imgB = tf.keras.layers.Input(shape=self.data.img_dims)\n",
        "\n",
        "        # get attention maps\n",
        "        # attnMapA = toZeroThreshold(AttnA(realA))\n",
        "        attA = TauThreshold(self.tau)(self.attA(imgA))\n",
        "        attB = TauThreshold(self.tau)(self.attB(imgB))\n",
        "        \n",
        "        # fgA = attnMapA * realA\n",
        "        imgA_fg = imgA * attA\n",
        "        imgB_fg = imgB * attB\n",
        "        \n",
        "        # bgA = (1 - attnMapA) * realA\n",
        "        imgA_bg = (1 - attA) * imgA\n",
        "        imgB_bg = (1 - attB) * imgB\n",
        "        \n",
        "        # IMAGE TRANSLATION\n",
        "        # genB = genA2B(fgA) \n",
        "        fakeA_fg = self.genA(imgB_fg)\n",
        "        fakeB_fg = self.genB(imgA_fg)\n",
        "        \n",
        "        # fakeB = (attnMapA * genB) + bgA\n",
        "        fakeB = fakeB_fg * attA + imgA_bg # s'\n",
        "        fakeA = fakeA_fg * attB + imgB_bg\n",
        "\n",
        "        # CYCLIC TRANSLATION\n",
        "        # get attention maps\n",
        "        # attnMapfakeB = toZeroThreshold(AttnB(fakeB))\n",
        "        attA_fake = TauThreshold(self.tau)(self.attA(fakeA))\n",
        "        attB_fake = TauThreshold(self.tau)(self.attB(fakeB))\n",
        "\n",
        "        # get the foreground\n",
        "        # fgfakeB = attnMapfakeB * fakeB\n",
        "        fakeA_fg = fakeA * attA_fake\n",
        "        fakeB_fg = fakeB * attB_fake\n",
        "\n",
        "        # get the background\n",
        "        # bgfakeB = (1 - attnMapfakeB) * fakeB\n",
        "        cyclicA_bg = (1 - attA_fake) * fakeA\n",
        "        cyclicB_bg = (1 - attB_fake) * fakeB\n",
        "        \n",
        "        # genA_ = genB2A(fgfakeB)\n",
        "        cyclicA_fg = self.genA(fakeB_fg)\n",
        "        cyclicB_fg = self.genB(fakeA_fg)\n",
        "        \n",
        "        # combine\n",
        "        # A_ = (attnMapfakeB * genA_) + bgfakeB\n",
        "        cyclicA = attB_fake * cyclicA_fg + cyclicB_bg # s''\n",
        "        cyclicB = attA_fake * cyclicB_fg + cyclicA_bg # s''\n",
        "        \n",
        "        # compile basic discriminators\n",
        "        self.disA.compile(loss='mse', optimizer=self.optimizer_d, metrics=['accuracy'])\n",
        "        self.disB.compile(loss='mse', optimizer=self.optimizer_d, metrics=['accuracy'])\n",
        "        self.disA_no_norm.compile(loss='mse', optimizer=self.optimizer_d, metrics=['accuracy'])\n",
        "        self.disB_no_norm.compile(loss='mse', optimizer=self.optimizer_d, metrics=['accuracy'])\n",
        "\n",
        "        #TODO attention to identity mappings? \n",
        "        # Identity mapping of images\n",
        "        # img1_id = self.gen2(img1)\n",
        "        # img2_id = self.gen1(img2)\n",
        "\n",
        "        # combined model only trains generators (and attention)\n",
        "        self.disA.trainable = False\n",
        "        self.disB.trainable = False\n",
        "        self.disA_no_norm.trainable = False\n",
        "        self.disB_no_norm.trainable = False\n",
        "\n",
        "        # discriminate the fake images\n",
        "        # stage 1 - whole image with normalisation\n",
        "        validityA_stage1 = self.disA(fakeA)\n",
        "        validityB_stage1 = self.disB(fakeB)\n",
        "        \n",
        "        cyclic_valA_stage1 = self.disA(cyclicA)\n",
        "        cyclic_valB_stage1 = self.disB(cyclicB)\n",
        "\n",
        "        # use dis without normalisation on the foreground only\n",
        "        validityA_stage2 = self.disA_no_norm(fakeA_fg)\n",
        "        validityB_stage2 = self.disB_no_norm(fakeB_fg)\n",
        "\n",
        "        cyclic_valA_stage2 = self.disA_no_norm(cyclicA_fg)\n",
        "        cyclic_valB_stage2 = self.disB_no_norm(cyclicB_fg)\n",
        "        \n",
        "        # build and compile combined model for stage 1\n",
        "        self.combined_model1 = tf.keras.Model(inputs=[imgA, imgB],\n",
        "                                             outputs=[validityA_stage1, validityB_stage1, cyclic_valA_stage1, cyclic_valB_stage1, cyclicA, cyclicB])#, img1_id, img2_id])\n",
        "        self.combined_model1.compile(optimizer=self.optimizer_g,\n",
        "                                    loss=['mse', 'mse', 'mse', 'mse', 'mae', 'mae'])#, 'mae', 'mae'],\n",
        "                                    #loss_weights=[1, 1, self.lambda_cyclic, self.lambda_cyclic])#, self.lambda_id, self.lambda_id])\n",
        "\n",
        "        # no more attention training in stage 2\n",
        "        self.attA.trainable = False\n",
        "        self.attB.trainable = False\n",
        "\n",
        "        # build and compile combined model for stage 2\n",
        "        self.combined_model2 = tf.keras.Model(inputs=[imgA, imgB],\n",
        "                                                    outputs=[validityA_stage2, validityB_stage2, cyclic_valA_stage2, cyclic_valB_stage2, cyclicA, cyclicB])#, img1_id, img2_id])\n",
        "        self.combined_model2.compile(optimizer=self.optimizer_g,\n",
        "                                           loss=['mse', 'mse', 'mse', 'mse', 'mae', 'mae'])#, 'mae', 'mae'],\n",
        "                                           #loss_weights=[1, 1, self.lambda_cyclic, self.lambda_cyclic])#, self.lambda_id, self.lambda_id])\n",
        "#         self.combined_model1.summary()\n",
        "#         print('_________-___________')\n",
        "#         self.combined_model2.summary()\n",
        "\n",
        "\n",
        "\n",
        "    def train(self, sample_interval=5):\n",
        "        \n",
        "        start_time = datetime.datetime.now()\n",
        "\n",
        "        # fake img pools for dis\n",
        "        self.fakeA_pool = ItemPool(size=self.pool_size)\n",
        "        self.fakeB_pool = ItemPool(size=self.pool_size)\n",
        "        self.fakeA_cyclic_pool = ItemPool(size=self.pool_size)\n",
        "        self.fakeB_cyclic_pool = ItemPool(size=self.pool_size)\n",
        "        \n",
        "        self.fakeA_fg_pool = ItemPool(size=self.pool_size)\n",
        "        self.fakeB_fg_pool = ItemPool(size=self.pool_size)\n",
        "        self.fakeA_cyclic_fg_pool = ItemPool(size=self.pool_size)\n",
        "        self.fakeB_cyclic_fg_pool = ItemPool(size=self.pool_size)\n",
        "        \n",
        "        # adversarial loss ground truth\n",
        "        valid = np.ones((self.data.batch_size,) + self.disc_patch)\n",
        "        fake = np.zeros((self.data.batch_size,) + self.disc_patch)\n",
        "\n",
        "        is_after_att_thres = False\n",
        "       \n",
        "        avg_loss_disA_real = tf.keras.metrics.Mean(name='loss_disA_real', dtype=tf.float32)\n",
        "        avg_loss_disA_fake = tf.keras.metrics.Mean(name='loss_disA_fake', dtype=tf.float32)\n",
        "        avg_loss_disA_cyclic = tf.keras.metrics.Mean(name='loss_disA_cyclic', dtype=tf.float32)\n",
        "        avg_loss_genA_cyclic = tf.keras.metrics.Mean(name='loss_genA_cyclic', dtype=tf.float32)\n",
        "        avg_loss_disA_total = tf.keras.metrics.Mean(name='loss_disA_total', dtype=tf.float32)\n",
        "        \n",
        "        avg_loss_disB_real = tf.keras.metrics.Mean(name='loss_disB_real', dtype=tf.float32)\n",
        "        avg_loss_disB_fake = tf.keras.metrics.Mean(name='loss_disB_fake', dtype=tf.float32)\n",
        "        avg_loss_disB_cyclic = tf.keras.metrics.Mean(name='loss_disB_cyclic', dtype=tf.float32)\n",
        "        avg_loss_genB_cyclic = tf.keras.metrics.Mean(name='loss_genB_cyclic', dtype=tf.float32)\n",
        "        avg_loss_disB_total = tf.keras.metrics.Mean(name='loss_disB_total', dtype=tf.float32)\n",
        "        \n",
        "        avg_loss_dis_total = tf.keras.metrics.Mean(name='loss_dis_total', dtype=tf.float32)\n",
        "        avg_loss_gen_total = tf.keras.metrics.Mean(name='avg_loss_dis_total', dtype=tf.float32)\n",
        "        \n",
        "        os.makedirs('summaries', exist_ok=True)\n",
        "        summary_writer = tf.summary.create_file_writer('summaries')\n",
        "        with summary_writer.as_default():\n",
        "          for epoch in range(self.train_start+1, self.epochs+1):\n",
        "              self.cur_epoch = epoch\n",
        "              if epoch >= self.att_epoch_thresh:\n",
        "                  is_after_att_thres = True\n",
        "\n",
        "              for batch_i in range(1, self.data.n_batches+1):\n",
        "                  imgA, imgB = self.data.load_batch()\n",
        "\n",
        "                  # GENERATE IMAGES\n",
        "                  # get attention maps\n",
        "                  # attnMapA = toZeroThreshold(AttnA(realA))\n",
        "                  attA = tau_thres(self.attA.predict(imgA), tau=self.tau)\n",
        "                  attB = tau_thres(self.attB.predict(imgB), tau=self.tau)\n",
        "\n",
        "                  # fgA = attnMapA * realA\n",
        "                  imgA_fg = imgA * attA\n",
        "                  imgB_fg = imgB * attB\n",
        "\n",
        "                  # bgA = (1 - attnMapA) * realA\n",
        "                  imgA_bg = (1 - attA) * imgA\n",
        "                  imgB_bg = (1 - attB) * imgB\n",
        "\n",
        "                  # IMAGE TRANSLATION\n",
        "                  # genB = genA2B(fgA) \n",
        "                  fakeA_fg = self.genA.predict(imgB_fg)\n",
        "                  fakeB_fg = self.genB.predict(imgA_fg)\n",
        "\n",
        "                  # fakeB = (attnMapA * genB) + bgA\n",
        "                  fakeB = fakeB_fg * attA + imgA_bg # s'\n",
        "                  fakeA = fakeA_fg * attB + imgB_bg\n",
        "\n",
        "                  # CYCLIC TRANSLATION\n",
        "                  # get attention maps\n",
        "                  # attnMapfakeB = toZeroThreshold(AttnB(fakeB))\n",
        "                  attA_fake = tau_thres(self.attA.predict(fakeA), tau=self.tau)\n",
        "                  attB_fake = tau_thres(self.attB.predict(fakeB), tau=self.tau)\n",
        "\n",
        "                  # get the foreground\n",
        "                  # fgfakeB = attnMapfakeB * fakeB\n",
        "                  fakeA_fg = fakeA * attA_fake\n",
        "                  fakeB_fg = fakeB * attB_fake\n",
        "\n",
        "                  # get the background\n",
        "                  # bgfakeB = (1 - attnMapfakeB) * fakeB\n",
        "                  cyclicA_bg = (1 - attA_fake) * fakeA\n",
        "                  cyclicB_bg = (1 - attB_fake) * fakeB\n",
        "\n",
        "                  # genA_ = genB2A(fgfakeB)\n",
        "                  cyclicA_fg = self.genA.predict(fakeB_fg)\n",
        "                  cyclicB_fg = self.genB.predict(fakeA_fg)\n",
        "\n",
        "                  # combine\n",
        "                  # A_ = (attnMapfakeB * genA_) + bgfakeB\n",
        "                  cyclicA = attB_fake * cyclicA_fg + cyclicB_bg # s''\n",
        "                  cyclicB = attA_fake * cyclicB_fg + cyclicA_bg # s''\n",
        "\n",
        "                  # TRAIN DISCRIMINATORS\n",
        "                  if is_after_att_thres:\n",
        "                      # pool management\n",
        "  #                     fakeA_fg_pool = self.fakeA_fg_pool.call(fakeA_fg)\n",
        "  #                     fakeB_fg_pool = self.fakeB_fg_pool.call(fakeB_fg)\n",
        "  #                     cyclicA_fg_pool = self.fakeA_cyclic_fg_pool.call(cyclicA_fg)\n",
        "  #                     cyclicB_fg_pool = self.fakeB_cyclic_fg_pool.call(cyclicB_fg)\n",
        "\n",
        "                      # discriminate only on the foreground\n",
        "                      # real losses\n",
        "                      real_predA = self.disA_no_norm.train_on_batch(imgA_fg, valid, sample_weight=np.array([2]))\n",
        "                      real_predB = self.disB_no_norm.train_on_batch(imgB_fg, valid, sample_weight=np.array([2]))\n",
        "\n",
        "\n",
        "                      # fake losses\n",
        "                      fake_predA = self.disA_no_norm.train_on_batch(fakeA_fg, fake)\n",
        "                      fake_predB = self.disB_no_norm.train_on_batch(fakeB_fg, fake)\n",
        "\n",
        "                      # fake cyclic losses\n",
        "                      cyclic_fake_predA = self.disA_no_norm.train_on_batch(cyclicA_fg, fake)\n",
        "                      cyclic_fake_predB = self.disB_no_norm.train_on_batch(cyclicB_fg, fake)\n",
        "                  else:\n",
        "                      # pool management\n",
        "  #                     fakeA_pool = self.fakeA_pool.call(fakeA)\n",
        "  #                     fakeB_pool = self.fakeB_pool.call(fakeB)\n",
        "  #                     cyclicA_pool = self.fakeA_cyclic_pool.call(cyclicA)\n",
        "  #                     cyclicB_pool = self.fakeB_cyclic_pool.call(cyclicB)\n",
        "\n",
        "\n",
        "                      # real loss\n",
        "                      real_predA = self.disA.train_on_batch(imgA, valid, sample_weight=np.array([2]))\n",
        "                      real_predB = self.disB.train_on_batch(imgB, valid, sample_weight=np.array([2]))\n",
        "\n",
        "                      # fake loss\n",
        "                      fake_predA = self.disA.train_on_batch(fakeA, fake)\n",
        "                      fake_predB = self.disB.train_on_batch(fakeB, fake) \n",
        "\n",
        "                      # cyclic fake loss\n",
        "                      cyclic_fake_predA = self.disA.train_on_batch(cyclicA, fake)\n",
        "                      cyclic_fake_predB = self.disB.train_on_batch(cyclicB, fake)\n",
        "\n",
        "                  # dis losses total\n",
        "                  disA_loss = adversarial_loss(real_predA, fake_predA, cyclic_fake_predA)\n",
        "                  disB_loss = adversarial_loss(real_predB, fake_predB, cyclic_fake_predA)\n",
        "                  dis_total_loss = disA_loss + disB_loss\n",
        "\n",
        "\n",
        "                  # TRAIN GENERATORS\n",
        "                  if is_after_att_thres:\n",
        "                      gen_loss = self.combined_model2.train_on_batch([imgA, imgB],\n",
        "                                                                           [valid, valid, valid, valid, imgA, imgB])#, imgs1, imgs2])\n",
        "                  else:\n",
        "                      gen_loss = self.combined_model1.train_on_batch([imgA, imgB],\n",
        "                                                                        [valid, valid, valid, valid, imgA, imgB])#, imgs1, imgs2])\n",
        "\n",
        "                  avg_loss_disA_real.update_state(real_predA)\n",
        "                  avg_loss_disB_real.update_state(real_predB)\n",
        "                  avg_loss_disA_fake.update_state(fake_predA)\n",
        "                  avg_loss_disB_fake.update_state(fake_predB)\n",
        "                  avg_loss_disA_cyclic.update_state(cyclic_fake_predA)\n",
        "                  avg_loss_disB_cyclic.update_state(cyclic_fake_predB)\n",
        "                  avg_loss_disA_total.update_state(disA_loss)\n",
        "                  avg_loss_disB_total.update_state(disB_loss)\n",
        "                  avg_loss_genA_cyclic.update_state(gen_loss[5])\n",
        "                  avg_loss_genB_cyclic.update_state(gen_loss[6])\n",
        "\n",
        "                  avg_loss_gen_total.update_state(gen_loss[0])\n",
        "                  avg_loss_dis_total.update_state(dis_total_loss)\n",
        "                  \n",
        "                  \n",
        "                  elapsed_time = datetime.datetime.now() - start_time\n",
        "                  if batch_i % 50 == 0:\n",
        "                      print(\n",
        "                          \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %05f] time: %s \" \\\n",
        "                          % (epoch, self.epochs,\n",
        "                             batch_i, self.data.n_batches,\n",
        "                             dis_total_loss,\n",
        "                             gen_loss[0],\n",
        "                             elapsed_time))\n",
        "                      \n",
        "                      \n",
        "                      tf.summary.scalar('avg_loss_disA_real', avg_loss_disA_real.result(), step=self.optimizer_g.iterations)\n",
        "                      tf.summary.scalar('avg_loss_disA_fake', avg_loss_disA_fake.result(), step=self.optimizer_g.iterations)\n",
        "                      tf.summary.scalar('avg_loss_disA_cyclic', avg_loss_disA_cyclic.result(), step=self.optimizer_g.iterations)\n",
        "                      tf.summary.scalar('avg_loss_genA_cyclic', avg_loss_genA_cyclic.result(), step=self.optimizer_g.iterations)\n",
        "                      tf.summary.scalar('avg_loss_disA_total', avg_loss_disA_total.result(), step=self.optimizer_g.iterations)\n",
        "                      tf.summary.scalar('avg_loss_disB_real', avg_loss_disB_real.result(), step=self.optimizer_g.iterations)\n",
        "                      tf.summary.scalar('avg_loss_disB_fake', avg_loss_disB_fake.result(), step=self.optimizer_g.iterations)\n",
        "                      tf.summary.scalar('avg_loss_disB_cyclic', avg_loss_disB_cyclic.result(), step=self.optimizer_g.iterations)\n",
        "                      tf.summary.scalar('avg_loss_genB_cyclic', avg_loss_genB_cyclic.result(), step=self.optimizer_g.iterations)\n",
        "                      tf.summary.scalar('avg_loss_disB_total', avg_loss_disB_total.result(), step=self.optimizer_g.iterations)\n",
        "                      tf.summary.scalar('avg_loss_dis_total', avg_loss_dis_total.result(), step=self.optimizer_g.iterations)\n",
        "                      tf.summary.scalar('avg_loss_gen_total', avg_loss_gen_total.result(), step=self.optimizer_g.iterations)\n",
        "\n",
        "                      avg_loss_disA_real.reset_states()\n",
        "                      avg_loss_disA_fake.reset_states()\n",
        "                      avg_loss_disA_cyclic.reset_states()\n",
        "                      avg_loss_genA_cyclic.reset_states()\n",
        "                      avg_loss_disA_total.reset_states()\n",
        "                      avg_loss_disB_real.reset_states()\n",
        "                      avg_loss_disB_fake.reset_states()\n",
        "                      avg_loss_disB_cyclic.reset_states()\n",
        "                      avg_loss_genB_cyclic.reset_states()\n",
        "                      avg_loss_disB_total.reset_states()\n",
        "                      avg_loss_dis_total.reset_states()\n",
        "                      avg_loss_gen_total.reset_states()\n",
        "\n",
        "                  # printing\n",
        "  #                 print(\n",
        "  #                     \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f] time: %s \" \\\n",
        "  #                     % (epoch + 1, self.epochs,\n",
        "  #                        batch_i + 1, self.data.n_batches,\n",
        "  #                        dis_total_loss[0], 100 * dis_total_loss[1],\n",
        "  #                        gen_loss[0],\n",
        "  #                        np.mean(gen_loss[1:3]),\n",
        "  #                        np.mean(gen_loss[3:5]),\n",
        "  #                        # np.mean(gen_loss[5:6]),\n",
        "  #                        elapsed_time))\n",
        "\n",
        "                  # If at save interval => save generated image samples\n",
        "                  if batch_i % 1000 == 0:\n",
        "                      it = batch_i // 1000\n",
        "                      self.sample_images(epoch, it)\n",
        "\n",
        "                      mod_name = 'full_orig'\n",
        "                      os.makedirs('model/%s/%s' % (self.data.name, mod_name), exist_ok=True)\n",
        "          #                 save_time = datetime.datetime.now()\n",
        "\n",
        "                      self.combined_model1.save_weights('model/{}/{}/combined1_{:03d}_{:d}.h5'.format(self.data.name, mod_name, epoch, it))\n",
        "                      self.combined_model2.save_weights('model/{}/{}/combined2_{:03d}_{:d}.h5'.format(self.data.name, mod_name, epoch, it))\n",
        "                      self.disA.save_weights('model/{}/{}/disA{:03d}_{:d}.h5'.format(self.data.name, mod_name, epoch, it))\n",
        "                      self.disB.save_weights('model/{}/{}/disB{:03d}_{:d}.h5'.format(self.data.name, mod_name, epoch, it))\n",
        "          #                 self.disA_no_norm.save_weights('model/%s/%s/disA_nn%d' % (self.data.name, mod_name, epoch))\n",
        "          #                 self.disB_no_norm.save_weights('model/%s/%s/disB_nn%d' % (self.data.name, mod_name, epoch))\n",
        "          #                 print('Saving models took: ' + str(datetime.datetime.now() - save_time))\n",
        "                      self.save_things_to_drive(epoch, it)\n",
        "\n",
        "\n",
        "    def load_weights(self, comb1_p, comb2_p, disA_p, disB_p):\n",
        "        self.combined_model1.load_weights(comb1_p)\n",
        "        self.combined_model2.load_weights(comb2_p)\n",
        "        self.disA.load_weights(disA_p)\n",
        "        self.disB.load_weights(disB_p)\n",
        "        \n",
        "        \n",
        "    def sample_images(self, epoch, it):\n",
        "#         os.makedirs('images/%s' % self.data.name, exist_ok=True)\n",
        "        r, c = 2, 9\n",
        "\n",
        "        imgA, imgB = self.data.sample_batch()\n",
        "\n",
        "        # attnMapA = toZeroThreshold(AttnA(realA))\n",
        "        attA = TauThreshold(self.tau)(self.attA.predict(imgA))\n",
        "        attB = TauThreshold(self.tau)(self.attB.predict(imgB))\n",
        "        \n",
        "        # fgA = attnMapA * realA\n",
        "        imgA_fg = imgA * attA\n",
        "        imgB_fg = imgB * attB\n",
        "        \n",
        "        # bgA = (1 - attnMapA) * realA\n",
        "        imgA_bg = (1 - attA) * imgA\n",
        "        imgB_bg = (1 - attB) * imgB\n",
        "        \n",
        "        # IMAGE TRANSLATION\n",
        "        # genB = genA2B(fgA) \n",
        "        fakeA_fg = self.genA.predict(imgB_fg)\n",
        "        fakeB_fg = self.genB.predict(imgA_fg)\n",
        "        \n",
        "        # fakeB = (attnMapA * genB) + bgA\n",
        "        fakeB = fakeB_fg * attA + imgA_bg # s'\n",
        "        fakeA = fakeA_fg * attB + imgB_bg\n",
        "\n",
        "        # CYCLIC TRANSLATION\n",
        "        # get attention maps\n",
        "        # attnMapfakeB = toZeroThreshold(AttnB(fakeB))\n",
        "        attA_fake = TauThreshold(self.tau)(self.attA.predict(fakeA))\n",
        "        attB_fake = TauThreshold(self.tau)(self.attB.predict(fakeB))\n",
        "\n",
        "        # get the foreground\n",
        "        # fgfakeB = attnMapfakeB * fakeB\n",
        "        fakeA_fg = fakeA * attA_fake\n",
        "        fakeB_fg = fakeB * attB_fake\n",
        "\n",
        "        # get the background\n",
        "        # bgfakeB = (1 - attnMapfakeB) * fakeB\n",
        "        cyclicA_bg = (1 - attA_fake) * fakeA\n",
        "        cyclicB_bg = (1 - attB_fake) * fakeB\n",
        "        \n",
        "        # genA_ = genB2A(fgfakeB)\n",
        "        cyclicA_fg = self.genA.predict(fakeB_fg)\n",
        "        cyclicB_fg = self.genB.predict(fakeA_fg)\n",
        "        \n",
        "        # combine\n",
        "        # A_ = (attnMapfakeB * genA_) + bgfakeB\n",
        "        cyclicA = attB_fake * cyclicA_fg + cyclicB_bg # s''\n",
        "        cyclicB = attA_fake * cyclicB_fg + cyclicA_bg # s''\n",
        "        \n",
        "        attA = 2 * (attA - 0.5)\n",
        "        attB = 2 * (attB - 0.5)\n",
        "        attA_fake = 2 * (attA_fake - 0.5)\n",
        "        attB_fake = 2 * (attB_fake - 0.5)\n",
        "        \n",
        "        attA = np.concatenate([attA] * 3, axis=3)\n",
        "        attB = np.concatenate([attB] * 3, axis=3)\n",
        "        attA_fake = np.concatenate([attA_fake] * 3, axis=3)\n",
        "        attB_fake = np.concatenate([attB_fake] * 3, axis=3)\n",
        "        \n",
        "#         print('imgA ' +  str(np.amax(imgA)) + \" - \" + str(np.amin(imgA)))\n",
        "#         print('attA ' + str(np.amax(attA)) + \" - \" + str(np.amin(attA)))\n",
        "#         print('fakeB ' + str(np.amax(fakeB)) + \" - \" + str(np.amin(fakeB)))\n",
        "#         print('cyclicA ' + str(np.amax(cyclicA)) + \" - \" + str(np.amin(cyclicA)))\n",
        "#         print('imgB ' + str(np.amax(imgB)) + \" - \" + str(np.amin(imgB)))\n",
        "#         print('attB ' + str(np.amax(attB)) + \" - \" + str(np.amin(attB)))\n",
        "#         print('fakeA ' + str(np.amax(fakeA)) + \" - \" + str(np.amin(fakeA)))\n",
        "#         print('cyclicB ' + str(np.amax(cyclicB)) + \" - \" + str(np.amin(cyclicB)))\n",
        "\n",
        "\n",
        "        gen_imgs = np.concatenate([imgA, attA, imgA_fg, fakeB_fg, fakeB, attB_fake, fakeB_fg, cyclicA_fg, cyclicA,\n",
        "                                   imgB, attB, imgB_fg, fakeA_fg, fakeA, attA_fake, fakeA_fg, cyclicB_fg, cyclicB])\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        titles = ['Original', 'Attention', 'Original fg', 'Translated fg', 'Translated', 'Attention', 'Fake fg', 'Cyclic fg', 'Cyclic']\n",
        "        fig, axs = plt.subplots(r, c, figsize=(64, 64))\n",
        "        \n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i, j].imshow(gen_imgs[cnt])\n",
        "                axs[i, j].set_title(titles[j])\n",
        "                axs[i, j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.tight_layout()\n",
        "        fig.savefig(\"output/{}/att{:0>3d}_{:d}.png\".format(self.data.name, epoch, it))\n",
        "        plt.close()\n",
        "        plt.clf() \n",
        "\n",
        "    def save_things_to_drive(self, epoch, it):\n",
        "        mod_name = 'full_orig'\n",
        "\n",
        "        file_paths = ['model/{}/{}/combined1_{:03d}_{:d}.h5'.format(self.data.name, mod_name, epoch, it),\n",
        "                     'model/{}/{}/combined2_{:03d}_{:d}.h5'.format(self.data.name, mod_name, epoch, it),\n",
        "                     'model/{}/{}/disA{:03d}_{:d}.h5'.format(self.data.name, mod_name, epoch, it),\n",
        "                     'model/{}/{}/disB{:03d}_{:d}.h5'.format(self.data.name, mod_name, epoch, it),\n",
        "                     \"output/{}/att{:0>3d}_{:d}.png\".format(self.data.name, epoch, it)]\n",
        "            \n",
        "        name = 'attGAN_orig_{:d}_{:d}.zip'.format(epoch, it)\n",
        "        with ZipFile(name,'w') as zip: \n",
        "            for file in file_paths: \n",
        "                zip.write(file)\n",
        "                \n",
        "#         upload = self.drive.CreateFile({\"title\":name})\n",
        "#         upload.SetContentFile('/content/' + name)\n",
        "#         upload.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDaXQ5WqvkA1",
        "colab_type": "text"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlAx6OAqvmQ4",
        "colab_type": "code",
        "outputId": "036fe123-a47a-4232-b9c6-3905dda23bd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# import os\n",
        "# import argparse\n",
        "\n",
        "class Dummy():\n",
        "    pass\n",
        "\n",
        "args = Dummy()\n",
        "args.dataset = 'sim2larvae'\n",
        "# args.datasets_dir = 'datasets'\n",
        "args.img_shape = 256\n",
        "args.patch = None\n",
        "args.batch_size = 1\n",
        "args.epochs = 33\n",
        "args.epoch_decay = 10\n",
        "args.lr_dis = 0.0002\n",
        "args.lr_gen = 0.0002\n",
        "args.beta1 = 0.5\n",
        "args.att = True\n",
        "args.att_epochs = 10\n",
        "args.tau = 0.1\n",
        "args.pool_size = 50\n",
        "args.sample_int = 1\n",
        "args.train_start = 0 # 0 for starting from scratch\n",
        "\n",
        "# output_dir\n",
        "if not os.path.exists('./output'):\n",
        "    os.makedirs('output')\n",
        "\n",
        "output_dir = './output/' + args.dataset\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# # save settings\n",
        "# with open(output_dir + '/args.yaml', 'w') as f:\n",
        "#     yaml.dump(args, f)\n",
        "\n",
        "data = Data_Loader(img_shape=(args.img_shape, args.img_shape, 3),\n",
        "                                  name=args.dataset,\n",
        "                                  patch=args.patch,\n",
        "                                  batch_size=args.batch_size)\n",
        "print(\"setting up...\")\n",
        "model = Model2(data_loader=data,\n",
        "                    epochs=args.epochs,\n",
        "                    lr_d=args.lr_dis,\n",
        "                    lr_g=args.lr_gen,\n",
        "                    beta1=args.beta1,\n",
        "                    epoch_decay=args.epoch_decay,\n",
        "                    pool_size=args.pool_size,\n",
        "                    load_from_checkpoint=False,\n",
        "                    use_att=args.att,\n",
        "                    tau=args.tau,\n",
        "                    attention_epochs_threshold=args.att_epochs,\n",
        "                    train_start=args.train_start)\n",
        "\n",
        "# p_root = \n",
        "# model.load_weights()\n",
        "\n",
        "print(\"training...\")\n",
        "model.train(sample_interval=args.sample_int)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting up...\n",
            "training...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMUU_eMvDzmf",
        "colab_type": "text"
      },
      "source": [
        "# Tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNNU8PPNXsGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! zip attGAN_orig_horse.zip output/horse2zebra/*\n",
        "! rm -r summaries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBFBRHDaXbD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# path = 'model/horse2zebra/att_resize_conv/'\n",
        "# # model.load_weights(path + 'combined115', path + 'combined215', path + 'disA15', path + 'disB15')\n",
        "# model.combined_model1.load_weights('weights1.h5')\n",
        "genA = model.genA\n",
        "genB = model.genB\n",
        "attA = model.attA\n",
        "attB = model.attB\n",
        "imgA, imgB = model.data.sample_batch()\n",
        "\n",
        "\n",
        "\n",
        "show_flow(genA, imgB)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpi8eP-ZHas8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "# from google.colab import auth\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq5UX5dcykuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gauth = GoogleAuth()\n",
        "# gauth.CommandLineAuth()\n",
        "# drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmORHGPMzQ7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! zip -r orig_horse2zebra output/horse2zebra"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}